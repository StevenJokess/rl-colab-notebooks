{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "stable_baselines_HER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenJokess/rl-colab-notebooks/blob/sb3/stable_baselines_her(colab).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Stable Baselines - Hindsight Experience Replay on Highway Env\n",
        "\n",
        "Github Repo: [https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
        "\n",
        "Highway env: [https://github.com/eleurent/highway-env](https://github.com/eleurent/highway-env) \n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a collection of pre-trained Reinforcement Learning agents using Stable-Baselines3.\n",
        "\n",
        "It also provides basic scripts for training, evaluating agents, tuning hyperparameters and recording videos.\n",
        "\n",
        "Documentation is available online: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)\n",
        "\n",
        "## Install Dependencies and Stable Baselines Using Pip\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines3[extra]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPg7pyvK_Emi",
        "outputId": "2b4b8e3b-e1aa-4e92-bc9d-b01f348e6c40"
      },
      "source": [
        "# Install stable-baselines latest version\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/DLR-RM/stable-baselines3\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-req-build-x8fgi2vo\n",
            "  Running command git clone -q https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-x8fgi2vo\n",
            "Requirement already satisfied (use --upgrade to upgrade): stable-baselines3==0.11.0a5 from git+https://github.com/DLR-RM/stable-baselines3 in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.6/dist-packages (from stable-baselines3==0.11.0a5) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines3==0.11.0a5) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from stable-baselines3==0.11.0a5) (1.7.0+cu101)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from stable-baselines3==0.11.0a5) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines3==0.11.0a5) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines3==0.11.0a5) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.17->stable-baselines3==0.11.0a5) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17->stable-baselines3==0.11.0a5) (1.5.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable-baselines3==0.11.0a5) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable-baselines3==0.11.0a5) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable-baselines3==0.11.0a5) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines3==0.11.0a5) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines3==0.11.0a5) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines3==0.11.0a5) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines3==0.11.0a5) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines3==0.11.0a5) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->stable-baselines3==0.11.0a5) (1.15.0)\n",
            "Building wheels for collected packages: stable-baselines3\n",
            "  Building wheel for stable-baselines3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable-baselines3: filename=stable_baselines3-0.11.0a5-cp36-none-any.whl size=150619 sha256=43d75c792bfc585e4dde2f165140cefd291545fa0ceb7be2418fc35d3a49569d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ddna5e4k/wheels/cf/89/6b/cd4b89427eb5ff0858bcba73911088d606c59eb3a97290b1bb\n",
            "Successfully built stable-baselines3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wA6lU254uNl",
        "outputId": "807092cd-18da-47fe-eb8e-5aa4993533ec"
      },
      "source": [
        "# Install highway-env\n",
        "!pip install git+https://github.com/eleurent/highway-env"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/eleurent/highway-env\n",
            "  Cloning https://github.com/eleurent/highway-env to /tmp/pip-req-build-6gshyyfd\n",
            "  Running command git clone -q https://github.com/eleurent/highway-env /tmp/pip-req-build-6gshyyfd\n",
            "Requirement already satisfied (use --upgrade to upgrade): highway-env==1.0.dev0 from git+https://github.com/eleurent/highway-env in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from highway-env==1.0.dev0) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from highway-env==1.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.6/dist-packages (from highway-env==1.0.dev0) (2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from highway-env==1.0.dev0) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from highway-env==1.0.dev0) (1.1.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->highway-env==1.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->highway-env==1.0.dev0) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->highway-env==1.0.dev0) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->highway-env==1.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->highway-env==1.0.dev0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->highway-env==1.0.dev0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->highway-env==1.0.dev0) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->highway-env==1.0.dev0) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->highway-env==1.0.dev0) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->highway-env==1.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: highway-env\n",
            "  Building wheel for highway-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for highway-env: filename=highway_env-1.0.dev0-cp36-none-any.whl size=80900 sha256=deb8c69065052a48dbcacc8070c1ca24279042f98f550bce341043c46bafe298\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pl4fcmj6/wheels/e6/10/d8/02a077ca221bbac1c6fc12c1370c2f773a8cd602d4be3df0cc\n",
            "Successfully built highway-env\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Import policy, RL agent, ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "source": [
        "import gym\n",
        "import highway_env\n",
        "import numpy as np\n",
        "\n",
        "from stable_baselines3 import HER, SAC, DDPG\n",
        "from stable_baselines3.common.noise import NormalActionNoise"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RapkYvTXL7Cd"
      },
      "source": [
        "## Create the Gym env and instantiate the agent\n",
        "\n",
        "For this example, we will be using the parking environment from the [highway-env](https://github.com/eleurent/highway-env) repo by @eleurent.\n",
        "\n",
        "The parking env is a goal-conditioned continuous control task, in which the vehicle must park in a given space with the appropriate heading.\n",
        "\n",
        "\n",
        "![parking-env](https://raw.githubusercontent.com/eleurent/highway-env/gh-media/docs/media/parking-env.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT5Io2LwAzlp"
      },
      "source": [
        "### Train Soft Actor-Critic (SAC) agent\n",
        "\n",
        "Here, we use HER \"future\" goal sampling strategy, where we create 4 artificial transitions per real transition\n",
        "\n",
        "Note: the hyperparameters (network architecture, discount factor, ...) were tuned for this task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzkK23C2BCKr"
      },
      "source": [
        "env = gym.make(\"parking-v0\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDdPRp0f5Bcz",
        "outputId": "abd6b5b9-7ab1-4d69-8208-237ab9fec6bc"
      },
      "source": [
        "# SAC hyperparams:\n",
        "model = HER('MlpPolicy', env, SAC, n_sampled_goal=4,\n",
        "            goal_selection_strategy='future', online_sampling=True,\n",
        "            verbose=1, buffer_size=int(1e6),\n",
        "            learning_rate=1e-3,\n",
        "            gamma=0.95, batch_size=256,\n",
        "            policy_kwargs=dict(net_arch=[256, 256, 256]), max_episode_length=100)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P82f568g5g0q",
        "outputId": "e2ade2d0-16ee-432d-cf93-7e1be974f837"
      },
      "source": [
        "# Train for 1e5 steps\n",
        "model.learn(int(2560)) #int(1e5)\n",
        "# Save the trained agent\n",
        "model.save('her_sac_highway')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -54.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 11       |\n",
            "|    total timesteps | 400      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.46    |\n",
            "|    critic_loss     | 0.0269   |\n",
            "|    ent_coef        | 0.742    |\n",
            "|    ent_coef_loss   | -1       |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 299      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 25       |\n",
            "|    total timesteps | 800      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.27    |\n",
            "|    critic_loss     | 0.0112   |\n",
            "|    ent_coef        | 0.497    |\n",
            "|    ent_coef_loss   | -2.34    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 699      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total timesteps | 1200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.96    |\n",
            "|    critic_loss     | 0.0106   |\n",
            "|    ent_coef        | 0.333    |\n",
            "|    ent_coef_loss   | -3.72    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 53       |\n",
            "|    total timesteps | 1600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.45    |\n",
            "|    critic_loss     | 0.00581  |\n",
            "|    ent_coef        | 0.224    |\n",
            "|    ent_coef_loss   | -5.01    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 67       |\n",
            "|    total timesteps | 2000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.19    |\n",
            "|    critic_loss     | 0.00655  |\n",
            "|    ent_coef        | 0.15     |\n",
            "|    ent_coef_loss   | -6.27    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 81       |\n",
            "|    total timesteps | 2400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.533   |\n",
            "|    critic_loss     | 0.0147   |\n",
            "|    ent_coef        | 0.102    |\n",
            "|    ent_coef_loss   | -7.1     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2299     |\n",
            "---------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGa3dNn36PTX",
        "outputId": "525711ed-26ef-49b4-9257-ec235ea56ac4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load saved model\n",
        "model = HER.load('her_sac_highway', env=env)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_7vKNGA6Hf"
      },
      "source": [
        "#### Evaluate the agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "D3sxhf1Q6NlL",
        "outputId": "906e6efd-6f56-4ec0-b891-e291948f6116"
      },
      "source": [
        "obs = env.reset()\n",
        "\n",
        "# Evaluate the agent\n",
        "episode_reward = 0\n",
        "for _ in range(10):# 1000\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    episode_reward += reward\n",
        "    if done or info[0].get('is_success', False):\n",
        "        print(\"Reward:\", episode_reward, \"Success?\", info[0].get('is_success', False))\n",
        "        episode_reward = 0.0\n",
        "        obs = env.reset()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f916d4d1d138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'is_success'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reward:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Success?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'is_success'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mepisode_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMjiWlSEi-3n"
      },
      "source": [
        "### Train DDPG agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCLW5cGIZa52",
        "outputId": "3c893e77-574f-432f-83a0-20d8ce6c6ee2"
      },
      "source": [
        "# Create the action noise object that will be used for exploration\n",
        "n_actions = env.action_space.shape[0]\n",
        "noise_std = 0.2\n",
        "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=noise_std * np.ones(n_actions))\n",
        "\n",
        "model = HER('MlpPolicy', env, DDPG, n_sampled_goal=4,\n",
        "            goal_selection_strategy='future', online_sampling=True,\n",
        "            verbose=1, buffer_size=int(1e6),\n",
        "            learning_rate=1e-3, action_noise=action_noise,\n",
        "            gamma=0.95, batch_size=256,\n",
        "            policy_kwargs=dict(net_arch=[256, 256, 256]), max_episode_length=100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXAQeENljBIe",
        "outputId": "b8fc6dc9-271d-44a4-f5a7-2ac309eff0ad"
      },
      "source": [
        "# Train for 2e5 steps\n",
        "model.learn(int(2560))\n",
        "# Save the trained agent\n",
        "model.save('her_ddpg_highway')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -50.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total timesteps | 400      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.383    |\n",
            "|    critic_loss     | 0.00158  |\n",
            "|    ent_coef        | 0.0872   |\n",
            "|    ent_coef_loss   | -7.69    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 200      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -54.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 37       |\n",
            "|    time_elapsed    | 21       |\n",
            "|    total timesteps | 800      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.803    |\n",
            "|    critic_loss     | 0.0215   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 600      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -63.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 32       |\n",
            "|    total timesteps | 1200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.62     |\n",
            "|    critic_loss     | 0.0344   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1000     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -63.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total timesteps | 1600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.89     |\n",
            "|    critic_loss     | 0.0252   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1400     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -66.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 55       |\n",
            "|    total timesteps | 2000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.22     |\n",
            "|    critic_loss     | 0.0308   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1800     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -64.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 67       |\n",
            "|    total timesteps | 2400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.3      |\n",
            "|    critic_loss     | 0.0296   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2200     |\n",
            "---------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o9N-V5FO2v2",
        "outputId": "6c0e6da2-22e5-4d6d-c008-33e50a4f8c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load saved model\n",
        "model = HER.load('her_ddpg_highway', env=env)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8uJjxQLBxdS"
      },
      "source": [
        "#### Evaluate the agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XjohypRhjEjS",
        "outputId": "679fc5ff-535c-4f45-f167-577a8e9650bf"
      },
      "source": [
        "obs = env.reset()\n",
        "\n",
        "# Evaluate the agent\n",
        "episode_reward = 0\n",
        "for _ in range(10): #1000\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    episode_reward += reward\n",
        "    if done or info[0].get('is_success', False):\n",
        "        print(\"Reward:\", episode_reward, \"Success?\", info[0].get('is_success', False))\n",
        "        episode_reward = 0.0\n",
        "        obs = env.reset()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1e0d9640961b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'is_success'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reward:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Success?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'is_success'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mepisode_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}